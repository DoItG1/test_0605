# actions/langchain_sql_bot.py

# ë„¤ ê¸°ì¡´ ì½”ë“œì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ import í•˜ë©´ ë¨!

import configparser
from sqlalchemy import create_engine
#from langchain_community.utilities import SQLDatabase
from langchain.utilities import SQLDatabase  # âœ… langchain==0.0.300 ì— ì¡´ì¬í•¨
#from langchain_experimental.sql import SQLDatabaseChain

# ? INI íŒŒì¼ ë¡œë“œ
gcConfigINI = r"C:\HIB70\HibConfig.ini"
gcpConfig = configparser.ConfigParser()
gcpConfig.read(gcConfigINI) 

# ? DB ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
gdicDbConnect = {
    'server': gcpConfig.get("DATABASE", "ServerName"),
    'user': gcpConfig.get("DATABASE", "DatabaseUser"),
    'password': gcpConfig.get("DATABASE", "DatabasePass"),
    'database': gcpConfig.get("DATABASE", "DatabaseName"),
    'driver' : '{ODBC Driver 17 for SQL Server}' # ë“œë¼ì´ë²„ëŠ” ì‚¬ìš©ìì˜ í™˜ê²½ì— ë§ê²Œ ì„¤ì •     
}

# ğŸ§± sqlalchemy URL ê°ì²´ ìƒì„± (ê¶Œì¥ ë°©ì‹)
connection_string = (
    f"DRIVER={gdicDbConnect['driver']};"
    f"SERVER={gdicDbConnect['server']};"
    f"DATABASE={gdicDbConnect['database']};"
    f"UID={gdicDbConnect['user']};"
    f"PWD={gdicDbConnect['password']}"
)

from sqlalchemy.engine import URL
import urllib
connection_url = URL.create(
    "mssql+pyodbc",
    query={"odbc_connect": urllib.parse.quote_plus(connection_string)},
)
engine = create_engine(connection_url)
db = SQLDatabase.from_uri(
                        connection_url,                        
                        include_tables=["PB_PERSON"]
                        )

#from langchain_community .llms import LlamaCpp
from langchain .llms import LlamaCpp
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory

# LlamaCpp ëª¨ë¸ êµ¬ì„±
MODEL_PATH = "D:\\Python\\LLAMA\\mistral-7b-instruct-v0.1.Q5_K_M.gguf"

LClim = LlamaCpp(
    model_path=MODEL_PATH,
    n_ctx=4096,
    temperature=0.7,
    max_tokens=512
)

ptPrompt = PromptTemplate(
    input_variables=["history", "input"],
    template="""
    ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ë³‘ì› EMR ì‹œìŠ¤í…œ ì‚¬ìš©ì ì§€ì› ì±—ë´‡ì´ì•¼.
    ë³‘ì› ì§ì›(ì˜ì‚¬, ê°„í˜¸ì‚¬, ì›ë¬´ê³¼ ì§ì› ë“±)ì´ EMR í”„ë¡œê·¸ë¨ ì‚¬ìš© ì¤‘ ê¶ê¸ˆí•œ ì‚¬í•­ì„ ì§ˆë¬¸í•˜ë©´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ ì¤˜.
    ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ê³ , ëª¨ë¥´ëŠ” ì§ˆë¬¸ì—ëŠ” "í•´ë‹¹ ë‚´ìš©ì€ í˜„ì¬ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."ë¼ê³  ë‹µë³€í•´.
    ì¿¼ë¦¬ë¥¼ ìƒì„±í•  ë•ŒëŠ” MS SQL ë¬¸ë²•ì„ ë”°ë¼ì„œ ë§Œë“¤ì–´ì¤˜

    ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡:
    {history}

    ì‚¬ìš©ì ì§ˆë¬¸: {input}

    ì±—ë´‡ ë‹µë³€:
    """
)
# Memory êµ¬ì„± (ëŒ€í™” íë¦„ ìœ ì§€)
cbmMemory = ConversationBufferMemory(memory_key="history")

# LLM Chain êµ¬ì„± â†’ ìš”ê²Œ ë°”ë¡œ llm_chain!
llm_chain = LLMChain(llm=LClim, prompt=ptPrompt, memory=cbmMemory)

# SQLDatabaseChain êµ¬ì„±
sql_prompt = PromptTemplate(
    input_variables=["query"],
    template="""
    ë„ˆëŠ” MS SQL ì „ë¬¸ê°€ì•¼. ì•„ë˜ ì§ˆë¬¸ì— ë§ëŠ” SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´.
    ë°˜ë“œì‹œ MS SQL ë¬¸ë²•ì„ ë”°ë¥´ê³ , ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ í•˜ì§€ ë§ê³  ì¿¼ë¦¬ë§Œ ì¶œë ¥í•´.

    ì§ˆë¬¸: {query}

    SQL ì¿¼ë¦¬:
    """
)
#db_chain = SQLDatabaseChain.from_llm(LClim, db, verbose=True)
db_chain = LLMChain(llm=LClim, prompt=sql_prompt)

faq_data = [
    {"question": "ë§ˆì•½ì²˜ë°©ì „ ì–´ë””ì—ì„œ ì¶œë ¥í•´?", "answer": "EMR í”„ë¡œê·¸ë¨ì˜ [ì²˜ë°©ì „ ì¶œë ¥] ë©”ë‰´ì—ì„œ ì¶œë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë©”ë‰´ ìœ„ì¹˜: ìƒë‹¨ ë°” > ì²˜ë°©ì „ ì¶œë ¥."},
    {"question": "í‡´ì›ìš”ì•½ì„œ ì¶œë ¥ì€ ì–´ë””ì„œ í•´?", "answer": "EMR í”„ë¡œê·¸ë¨ ë‚´ [ì§„ë‹¨ì„œ/ì¦ëª…ì„œ ë°œê¸‰] ë©”ë‰´ì—ì„œ í‡´ì›ìš”ì•½ì„œ ì¶œë ¥ ê°€ëŠ¥."},
    {"question": "ê²€ì‚¬ê²°ê³¼ ì–´ë””ì„œ ì¡°íšŒí•´?", "answer": "EMR í”„ë¡œê·¸ë¨ì˜ [ê²€ì‚¬ê²°ê³¼ ì¡°íšŒ] ë©”ë‰´ì—ì„œ ê²°ê³¼ í™•ì¸ ê°€ëŠ¥."}
]

# í†µê³„ SQL í…œí”Œë¦¿ ê²½ë¡œ
import pandas as pd
import json
import os

TEMPLATE_DIR = "query_templates"
MAPPING_FILE = os.path.join(TEMPLATE_DIR, "mapping.json")

# í…œí”Œë¦¿ ë§¤í•‘ ë¡œë“œ
with open(MAPPING_FILE, "r", encoding="utf-8") as f:
    QUERY_MAP = json.load(f)

def load_template(keyword: str) -> str:
    filename = QUERY_MAP.get(keyword)
    if not filename:
        return None
    path = os.path.join(TEMPLATE_DIR, filename)
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

from datetime import datetime
import dateparser
import re
    
# 2. ì§ˆë¬¸ ë¶„ì„ í•¨ìˆ˜
def extract_params(question):
    date_text = re.search(r"(ì§€ë‚œë‹¬|[0-9]{1,2}ì›”|ì˜¬í•´|ì‘ë…„)", question)
    dtype = "ì…ì›" if "ì…ì›" in question else "ì™¸ë˜" if "ì™¸ë˜" in question else "ì „ì²´"
    standard = "ì²˜ë°©" if "ì²˜ë°©" in question else "ì§„ë‹¨" if "ì§„ë‹¨" in question else "ì „ì²´"

    if date_text:
        dt = dateparser.parse(date_text.group())
        if dt:
            start = dt.replace(day=1)
            end = (start.replace(month=start.month % 12 + 1, day=1) - pd.Timedelta(days=1))
        else:
            start, end = datetime.now(), datetime.now()
    else:
        start, end = datetime.now(), datetime.now()

    return {
    "DATE": start.strftime('%Y-%m-%d'),
    "DATE_FROM": start.strftime('%Y-%m-%d'),
    "DATE_TO": end.strftime('%Y-%m-%d'),
    "TIME_FROM": start.strftime('%H:%M:%S'),
    "TIME_TO": end.strftime('%H:%M:%S'),
    "DATETIME_FROM": start.strftime('%Y-%m-%d %H:%M:%S'),
    "DATETIME_TO": end.strftime('%Y-%m-%d %H:%M:%S'),
    "TYPE": dtype,
    "STANDARD": standard
    }    
    
# FAISS
#from langchain_community.vectorstores import FAISS
#from langchain_community.document_loaders import TextLoader
from langchain.vectorstores import FAISS
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

#from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.embeddings import HuggingFaceEmbeddings
#from langchain_core.documents import Document
#from langchain.docstore.document import Document  # langchain==0.0.300 ì—ì„œëŠ” ì´ë ‡ê²Œ ì‚¬ìš©
from langchain.chains import RetrievalQA

INDEX_PATH = "menus_index"
TXT_FILE = "utf8HowToUseHIB.txt"

# ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ë¬¸ì„œ ë³€í™˜
# docs = [Document(page_content=f"{item['question']}###{item['answer']}") for item in faq_data]

# FAISS index ìƒì„±
# faiss_index = FAISS.from_documents(docs, embeddings)

# index ì €ì¥ (ì›í•˜ë©´ ë‚˜ì¤‘ì— ë¡œë“œ ê°€ëŠ¥)
# faiss_index.save_local("faiss_index")

# 2. FAISS ì¸ë±ìŠ¤ ë¡œë“œ or ìƒì„±
if os.path.exists(INDEX_PATH):
    print("ğŸ“‚ ì €ì¥ëœ ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
    #vectordb = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
    vectordb = FAISS.load_local(INDEX_PATH, embeddings)
else:
    print("ğŸ“„ ë©”ë‰´ ë¬¸ì„œë¡œë¶€í„° ì¸ë±ìŠ¤ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
    loader = TextLoader(TXT_FILE, encoding="utf-8-sig")
    documents = loader.load()

    splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)
    docs = splitter.split_documents(documents)

    vectordb = FAISS.from_documents(docs, embeddings)
    vectordb.save_local(INDEX_PATH)
    print("âœ… ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ!")

# 3. QA ì²´ì¸ êµ¬ì„±
retriever = vectordb.as_retriever(search_type="similarity", k=3)
faq_chain = RetrievalQA.from_chain_type(
    llm=LClim, 
    retriever=retriever
)

from sqlalchemy import text
from collections import defaultdict
from tenacity import retry, wait_random_exponential, stop_after_attempt, RetryError #TIME OUT ê¸°ëŠ¥ ì¶”ê°€

# ğŸ’¡ ì¬ì‹œë„ ë˜í¼ í•¨ìˆ˜
@retry(
    wait=wait_random_exponential(min=1, max=10),  # 1~10ì´ˆ ì‚¬ì´ ëœë¤ ëŒ€ê¸°
    stop=stop_after_attempt(3),                   # ìµœëŒ€ 3ë²ˆ ì‹œë„
)
def safe_llm_call(llm, prompt):
    print("ğŸ’¬ LLM í˜¸ì¶œ:", prompt)
    return llm.invoke(prompt)

import csv
import os
from datetime import datetime

LOG_FILE = "chat_log.csv"

def append_chat_log(user_text: str, bot_text: str):
    """CSV íŒŒì¼ì— ëŒ€í™” ë¡œê·¸ ì¶”ê°€"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    file_exists = os.path.isfile(LOG_FILE)

    with open(LOG_FILE, mode='a', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(["timestamp", "user", "bot"])
        writer.writerow([timestamp, user_text, bot_text])    
        
def get_generated_sql(intermediate):
    if not intermediate:
        return "-- ì—†ìŒ --"
    # first = intermediate[0]
    # if isinstance(first, dict):
    #    return first.get("sql_cmd", "-- ì—†ìŒ --")
    # elif isinstance(first, str):
    #     return first
    for step in intermediate:
        if isinstance(step, dict) and "sql_cmd" in step:
            return step["sql_cmd"]
        elif isinstance(step, str) and "SELECT" in step.upper():
            return step.strip()  # SQLë¬¸ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ë¬¸ìì—´ ë°˜í™˜
    return "-- ì—†ìŒ --"  

# FAQ ê²€ìƒ‰ í•¨ìˆ˜
def search_faq(user_question):
    docs = vectordb.similarity_search(user_question, k=1)
    if docs:
        return docs[0].page_content.strip()
    return None

# Routing í•¨ìˆ˜
def route_query(query: str) -> str:
    if not query:
        return "unknown"
    if any(k in query for k in QUERY_MAP):
        return "template"
    elif any(x in query for x in ["í†µê³„", "ê±´ìˆ˜", "ìˆ˜ëŸ‰", "ì˜ìˆ˜", "ì°¨íŠ¸", "ëŒ€ì¥", "ë¶„ì„", "ë³´ê³ ì„œ"]):
        return "langchain_sql"
    else:
        return "general"

# Rasaì—ì„œ í˜¸ì¶œí•  í†µí•© ì²˜ë¦¬ í•¨ìˆ˜
def process_query(user_input: str) -> str:
    print(f"[DEBUG] process_query() called with input: {user_input}")  # âœ… ìš”ê±° ì¶”ê°€
    query_type = route_query(user_input)
    print(f"[DEBUG] route_query() ê²°ê³¼: {query_type}")                 # âœ… ìš”ê²ƒë„ ì¶”ê°€í•´ë³´ì

    if query_type == "template":
        try:
            matched_key = next(k for k in QUERY_MAP if k in user_input)
            sql_template = load_template(matched_key)
            if sql_template:
                params = extract_params(user_input)
                sql = sql_template.format_map(defaultdict(str, params))
                with engine.connect() as conn:
                    result = conn.execute(text(sql))
                    rows = result.fetchall()
                    if not rows:
                        return "â— ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
                    else:
                        output = []
                        for row in rows:
                            output.append(str(row))
                        return "\n".join(output)
            else:
                return "â— í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            return f"ğŸš¨ SQL ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"

    elif query_type == "langchain_sql":
        try:
            #from langchain_core.runnables import Runnable
            #if isinstance(db_chain, Runnable):
            #    sql_response = db_chain.invoke({"query": user_input})
            #else:
            sql_response = db_chain.run(user_input)
                
            print("ìƒì„±ëœ SQL ì¿¼ë¦¬:", sql_response)

            # ê·¸ ë‹¤ìŒ SQL ì¿¼ë¦¬ ì‹¤í–‰ (SQLDatabase ì‚¬ìš©)
            with engine.connect() as conn:
                result = conn.execute(text(sql_response))
                rows = result.fetchall()

                if not rows:
                    print("â— ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    for row in rows:
                        print(row)
            
            result_text = sql_response.get("result", "-- ê²°ê³¼ ì—†ìŒ --")
            return result_text
        except Exception as e:
            return f"ğŸš¨ LangChain SQL ì˜¤ë¥˜: {str(e)}"

    elif query_type == "general":
        docs = vectordb.similarity_search(user_input, k=1)
        if docs:
            result = faq_chain.run(user_input)
            return result
        else:
            llm_result = llm_chain.run(input=user_input)
            return llm_result

    else:
        return "â“ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."
